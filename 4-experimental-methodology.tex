\chapter{Experimental Methodology}
After review of the background of near-Earth asteroid surveys and the existing body of literature for modelling surveys, this chapter will discuss the developed simulation in more detail. Firstly, in \autoref{sec::methdologysimulation}, the architecture of the simulation is discussed on a top-level. Then, in \autoref{sec:methdologyimplementation}, the implementation of the components of the simulation based on the literature in \autoref{ch:surveymodelling} is explained. Then, discourse will be given to the methods of optimization utlized in the research in \autoref{sec:methodologyoptimization}. Lastly, in \autoref{sec:methodologyprocess}, the process of using the simulation and optimization methods to obtain the results and conclusions presented in the next chapter is explained as well as the reasoning to support the optimization results. For reference, the interested reader can find the complete code as-is \href{https://github.com/ArjanVermeulen97/thesis/tree/main/code}{on Github.}

\section{Simulation Overview}
\label{sec:methodologysimulation}
First, before discussing the specifics of implementation, a general overview of the simulation is given. The objective of the simulation is to accurately predict the performance of a NEA survey by a given system of spacecraft, on a given population. Any optimization or validation is not considered a part of the simulation, but rather a system utilizing it. This will be further explained in \autoref{sec:methdologyprocess}.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=0.7\textwidth]{img/simulation_overview.png}
 \caption{Overview of the simulation architecture and main loops.}
 \label{fig:simulation_overview}
\end{figure}

The architecture of the simulation is shown in \autoref{fig:simulation_overview}. On the top left, the main input parameters to the model are displayed. These are primarily the spacecraft and asteroid properties. Both of these consist of a full set of Keplerian orbital elements per spacecraft or asteroid. The asteroid properties furthermore include the albedo, size, and absolute magnitude of each asteroid; the spacecraft properties include which type of payload the spacecraft is carrying. \\

The simulation consists of a nested loop. Firstly, at the start of each timestep (the time between the timesteps is determined by the survey cadence), the positions of all asteroids and spacecraft are determined by propagation of their orbital elements. Then, in the inside loop, each spacecraft is checked against each asteroid to see if it can detect said asteroid. This is done through calculation of the signal-to-noise ratio (SNR). Lastly, as it is known which asteroids got succesfully detected by which spacecraft, it can be determined if asteroids have been identified. Then, at the end of the simulation, the result is a list of the asteroid population in addition to whether they have been detected, and if so, when. Of course, this data can be further processed.

\section{Implementation}
\label{sec:methodologyimplementation}
In this section, the implementation of the simulation algortihm is discussed. The simulation was written fully in Python 3.8, for reasons of easy testing and iteration, availability of packages for data handling and analysis, and familiarity of the author. The simulations were ran on several computers equipped with consumer-grade 6-core CPU's. \\

With regards to specific packages, data handling and computation was performed using \href{https://pandas.pydata.org}{Pandas} and \href{https://numpy.org}{NumPy}. Parallelization was performed using \href{https://dask.org}{Dask}. Critical paths of these packages are written in C/C++/Cython, vastly improving the performance of the simulation. Optimization was implemented through \href{https://pypi.org/project/scikit-optimize}{Scikit-optimize} and \href{https://scikit-learn.org/stable/index.html}{Scikit-learn}. Where necessary for the purpose of analysis, data visualisation was performed using \href{https://seaborn.pydata.org}{Seaborn}. Several other packages were used, but their exact functionality and specification is not relevant for the implementation and operation of the simulation.

\subsection{Population of Asteroids, Spacecraft, and Orbital Mechanics}
The population of asteroids was implemented based on the work of \cite{GranvikPopulation}. The authors \href{http://www.iki.fi/mgranvik/data/Granvik+\_2018\_Icarus}{provide an already generated population model} of 802,000 NEA's of absolute magnitude $17 < H < 25$. This saves having to implement and validate their modelling separately. For the simulation, a random sample of asteroids is drawn for each simulation run. It was found that a number of 1000 asteroids provided adequate accuracy while reducing computational load. For validation runs, 2500 asteroids were sampled instead to ensure a higher level of accuracy. The model includes for each NEA a unique identifier, a set of six keplerian orbital elements, the absolute magnitude, and the albedo. The data is implemented as a Pandas dataframe. Similarly, the spacecraft are also implemented as a Pandas dataframe, although their orbital elements and payload are given as input arguments to the simulation. \\

Orbits of asteroids and spacecraft were modelled using Keplerian orbits. As no complex mission gemetries or three-body interactions such as impacts are being studied, it was assumed that this would provide an accurate representation. The transcendental Kepler equation was solved numerically using the iterative method proposed by \cite{KeplerEquation}. Resulting orbits and transformations were verified manually. It is noted that calculation of the position of asteroids and spacecraft, especially solving of the Kepler equation, presents one of the largest contributors to the simulation's runtime. For future work, an alternative implementation is recommended.

\subsection{Background Signal}
Implementation of the background signal as described in \autoref{sec:modelling_background} was carried out as follows: Data for visual light is directly provided in the work of \cite{LightOfTheNightSky} in tabulated format for a longitude range of $[0^\circ, 360^\circ]$, in intervals of $10^\circ$. Latitude coordinates are provided in the interval $[-90^\circ, 90^\circ]$, in intervals of $10^\circ$. Additionally, latitude values of $-15^\circ, -5^\circ, -2^\circ, 2^\circ, 5^\circ, 15^\circ$ are provided for additional detail around the brightest areas (such as the galactic core or the Sun). Background signal originating from the Sun uses eclitic coordinates, signal from the background stars use galactic coordinates. After manual verification, the tables were saved. \\

The thermal infrared signal as described in \cite{IRDust} was implemented in two steps. Firstly, the thermal infrared background signal from outside the solar system was loaded, and the model for interplanetary dust and sunlight for the Sun-dependent portion of the background signal was implemented. For the latter, the required line-of-sight integration was performed numerically using a Riemann sum with a step size of $0.1~\mathrm{AU}$, up to a distance of $5.2~\mathrm{AU}$ from the Sun. Results were verified manually by inspection, and comparison of locations of well-known objects in the Milky Way to their locations in the background star signal. The latter step was taken to also ensure that the transformation from ecliptic to galactic coordinates was performed correctly. After verification, the resulting data was tabulated for the same longitude and latitude combinations as the visual light background signal. This was done to ensure universal operation of the code, reducing errors, and to avoid the computational load associated with processing the highly detailed \textit{COBE} data and performing the abovementioned numerical integration. \\

After tabulation, the background signal data can be held in memory during operation. Where necessary, it can be corrected to account for the spacecraft's distance from the Sun using \autoref{eq:sunscale}. When necessary, the value of the signal is determined from interpolation by means of Scikit's linear N-dimensional interpolator. \autoref{fig:combinedvisbackground} and \autoref{fig:combinedtirbackground} show the resulting background signal in the visual light and thermal infrared, respectively. It can be seen that some loss of detail in the thermal infrared is incurred due to the tabulation, however the effect is minor.

\begin{figure}[htbp]
 \centering
 \includegraphics[width=1.0\textwidth]{img/background_vis_combined.png}
 \caption{Background signal in the visual spectrum, in ecliptic coordinates, as seen from a spacecraft located at (-1, 0, 0) AU. Units are $S10_\odot$ or solar-type stars of 10th magnitude per square degree. $1~S10_\odot = 9.00~\mathrm{W}~\mathrm{m}^{-2}~\mathrm{Sr}^{-1}$. The scale is clipped at $1000 ~S10_\odot$ for clarity.}
 \label{fig:combinedvisbackground}
\end{figure}

\begin{figure}[htbp]
 \centering
 \includegraphics[width=1.0\textwidth]{img/background_tir_combined.png}
 \caption{Background signal in thermal infrared, in ecliptic coordinates, as seen from a spacecraft located at (-1, 0, 0) AU. Units are Megajansky per steradian, $1 ~\mathrm{MJy}~{sr}^{-1} = 10^{-21} ~\mathrm{W}~\mathrm{m}^{-2}~\mathrm{Hz}^{-1}~\mathrm{Sr}^{-1}$, and the scale is clipped at $35 ~\mathrm{MJy}~{sr}^{-1}$ for clarity.}
 \label{fig:combinedtirbackground}
\end{figure}

\subsection{Target Signal}
Implementation of target signal is a straightforward process. For the visual spectrum, the formulae listed in \autoref{sec:modelling_target} could be directly copied. The thermal infrared signal involves a triple integration, and is slightly more complex. As this process has to be performed $n_{asteroids} * n_{spacecraft} * T_{simulation} / \Delta t$ times per simulation, performance has to be taken into account when implementing the integrations. \\

Firstly, the integration of Planck's law over the bandpass. No closed-form solution exists for the definite integral of Planck's law. As Planck's law is relatively smooth, the decision was made to approximate the integral by the average of the start and end of the bandpass. In practice this means:
\begin{equation}
 \int _{6 \mu\mathrm{m}}^{10 \mu\mathrm{m}} B(\lambda, T) d\lambda \approx \frac{1}{2}\left[B(6 \mu\mathrm{m}, T) + B(10 \mu\mathrm{m}, T)\right] \Delta \lambda
\end{equation}
This essentially approximates Planck's law as a linear function in the domain. It is assumed that this is accurate for the range and temperatures considered. This simplification has to be made, as this integration has to be carried out for every part of the numerical integration over the visible hemisphere of the asteroid, and is thus performed even more often per simulation (in fact, it is the most-called function in the simulation). The integration over the visual hemisphere of the asteroid is performed by first assuming the asteroid to be a sphere. From geometry this integral is well known:
\begin{equation}
 F(x) = R^2\int_{-\pi/2}^{\pi/2}\int_{-\pi/2}^{\pi/2} f(x) \cos \theta \cos \phi d \theta d \phi
\end{equation}
This integration was implemented through a Riemann sum as well, using the midpoint rule and an interval of $\pi/4$ for both directions, resulting in a total of 16 evaluations. It was found that the error with respect to a very precise integration was less than 1\%. Examples of the implementation can be seen in FIGUREEEE


\subsection{Search Strategy and Cadence}
Implementation of the search strategy and cadence proved to be the most problematic aspect in the implementation process. As mentioned in \autoref{sec:modelling_cadence}, very little literature exists on the topic, and no methods have been developed to obtain an optimal search strategy utilizing multiple spacecraft. Several options were considered to model the strategy and resulting cadence. Firstly, a method omitting implementation, instead performing a correction ex post, such as utlized by \cite{ThesisOlga}. This method was expected to underrepresent the effect of a distinct survey cadence, and introduces a look-ahead bias which would both be very problematic for the acccuracy of the results of this simulation. Secondly, explicitly modelling a north-to-south, west-to-east gridsearch-like strategy such as described by \cite{NEOCam}. Although this model would arguably be the most accurate, it is very impactful with respect to the computational load, for three reasons:
\begin{itemize}
 \item Firstly, the positions of the asteroids and spacecraft have to be calculated for each imaging step. This results in calculating the positions $41,253 / (7.13*1.7) \approx 3400$ times for thermal infrared, or 734 times for the visual spectrum, for each complete scan of the sky.
 \item Secondly, to check whether or not an asteroid is inside the field-of-view of the telescope, trigonometric calculations are necessary, which are computationally inefficient.
 \item Lastly, the conditional logic required to select only asteroids inside the field-of-view prevents parallelization and vectorization of critical parts of the computation.
\end{itemize}
In addition, as mentioned previously, an optimized multi-spacecraft search strategy would not utilize such a methodology in reality either. Therefore, the claim to increased accuracy is not useful, and not neccessarily representative of how the real system would function. The last option considered, which was the one ultimately implemented, is discretization of the entire cadence into a single imaging step, essentially neglecting the search strategy altogether. In practice, this means that instead of modelling out the time per image, the entire timestep of the simulation becomes equal to the cadence, and all asteroids are imaged at the same time once in that interval. For example, for a thermal infrared system with an integration time of $150~\mathrm{s}$, and a survey cadence of $21$ days, this would mean that instead of taking one $7.13^\circ x1.7^\circ$ image every $150~\mathrm{s}$ of a select portion of the sky (one image at t=0, second image at t=150s, third image at t=300s etc.), one ``image'' is taken of the full sky every 21 days (one image at t=0, one image at t=21 days, one image at t=42 days, etc.). This might seem to induce a very large discretization error. However, the magnitude of this error is limited:
\begin{itemize}
 \item An asteroid might move out of the detectable range within the 21 day interval. In this case the assumption causes the asteroid to not be detected. However, conversely, an asteroid might also move into the detectable range in this time period. Assuming both phenomena to be approximately equally common, the error in predicted performance should be small.
 \item An asteroid might move in the direction of the imaging, causing it to be detected twice in two different fields-of-view, decreasing the time needed to identify the asteroid by providing a second observation within the 21 day window. Again, the converse might also happen with an asteroid being ``missed'' in this way. Although it might seem this error is therefore also negligible, it is actually not, as most bodies in the Solar system (including NEA's) orbit the Sun counter-clockwise, and therefore a counter-clockwise survey will have slightly more occurences of double detections than missed detections. Still, considering the relative velocity between the NEA and the spacecraft means that this will also be a rare process.
 \item Lastly, a quantization error is present due to the maximum window between observations (see \autoref{sec:modelling_identification}). Given e.g. a 90-day maximum period between observations, a discretized survey with a 21-day cadence virtually only has a window of 84 days, as the next observation occurs at t=105 days, and is thus outside the 90-day window. It is expected that this will lead to an underestimation of the survey performance, although the influence is also minor, as a repeat observation at 85 days < t < 90 days, when it was not possible to obtain two follow-up observations prior to this is rare, as the period between close approaches of the NEA and the spacecraft will be in the order of hundreds to thousands of days.
\end{itemize}
Although the above examples are given for a 21-day thermal infrared survey, it is also of note that the error will be significantly smaller in a visual light system due to the faster cadence. In addition, the error is expected to be roughly equal in magnitude for all simulations, and therefore will have little influence on the optimization process. Considering also the fact that this assumption will provide an estimated 5,000 - 10,000 times faster simulation, this implementation was selected as the best option. The actual effect of the assumption will be validated in REFFF


\subsection{Signal-to-noise, Detection and Identification}
Implementation of the SNR from the target signal, background signal, and hardware properties could be executed directly using the formulae presented in \autoref{sec:modelling_hardware_SNR}. However, the probabilistic detection model utilizes an integrated Gaussian distribution. As this has no closed-form solution, an approximation based on the hyperbolic tangent function (\cite{GaussianTanh}) was implemented. The function was only applied in the $1 > SNR > 5$ range. An SNR < 1 leads to an automatic failure in detection, and an SNR > 5 to an automatic success. \\

For identification, the number and period of the detections are tracked in the asteroid parameters dataframe. For reasons previously outlined, a maximum observation interval of 90 days was assumed. Two criteria can lead to a succesful identification:
\begin{itemize}
 \item Detection on three different timesteps within 90 days by at least one spacecraft. Note that it is not neccessary that all three detections are made by the \textit{same} spacecraft.
 \item Detection on two different timesteps within 90 days, by at least two spacecraft. Again, it is not necessary that these are the same spacecraft. In addition, it is assumed that the triangulation process is always possible: as the sensors have a pixel scale in the order of 1 arcsecond, colinearity is assumed to be a negligible phenomenon.
\end{itemize}

This means that all communication and image processing requirements are left out of the scope of the simulation. Such requirements, e.g. that the datarate between spacecraft is high enough that they can transmit observations to eachother, and that images can be processed on-board, would be design requirements for an eventual mission, such as also already outlined by \cite{2017NEOSDT}.

\section{Optimization Methods}
\label{sec:methdologyoptimization}
In order to obtain the optimal solutions to the problem, the simulation will be used in conjunction with a mathmatical optimizer. A plethora of optimizers exist to date, however a selection of promising optimization methods could be made fairly easily. Firstly, a large number of optimizers, the so-called gradient methods, are reliant on the availability of an analytical solution for the derivative of the function. No way of analytically evaluating the derivative of the simulation was found, and it is expected it does not exist due to the complexity. A second class of optimizers which is subsequently often considered are the heuristic-based methods, such as particle swarm optimization, simulated annealing, and genetic/evolutionary methods. However, these methods are firstly not guaranteed to find the global optimum, and secondly, require a very large number of function evaluations. Especially the latter is a problem, as the function is a full simulation, which is far from computationally trivial as shown in the previous sections. \\

Therefore, it was decided to implement a solution from the class of \textit{surrogate optimization} methods. In these methods, A more simple function is fit to the to-be-optimized function, and it is optimized instead as this allows using a more effective optimizer that can not be used on the function of interest, thereby limiting the number of required evaluations of the main function. The resulting queries to the main function are then used to update the surrogate function. As the surrogate function will eventually very closely resemble the main function, the method is guaranteed to approach the global minimum, provided the function is sufficiently smooth, can be evaluated in the entire domain, and does not have noise (\cite{Surrogate}).

\section{Experimental Process}
\label{sec:methodologyprocess}
